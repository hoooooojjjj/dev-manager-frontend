---
description:
globs:
alwaysApply: false
---

# PRD - 개발 착수 전 단계(PRD→개발 명세서→AI 실행 프롬프트)

## AI 구동 이직 풀 매니지먼트 – 업무 효율/성과 극대화 모듈 (PRD v1)

작성자: 유호준 (프론트엔드 메인 풀스택)
스택: Next.js (App Router) · NestJS · MCP(Notion/GitHub/Brave) · **MySQL 8.x** · Redis(BullMQ)
범위: **개발 착수 전 단계**(PRD→개발 명세서→AI 실행 프롬프트)까지. 블로그/이력서 자동화와 클라우드 스토리지(S3 등) 의존은 후속 단계.

---

## 0. 문제 정의 & 제품 비전

- **문제**: 현업에서 “문제를 어떻게 정의→어떻게 해결→어떤 성과를 냈는지”를 일관되게 수행·기록하기 어렵다. 특히 개발 착수 전, PRD를 개발적으로 해석·분해하고 고품질 레퍼런스를 사전 확보하는 과정이 비체계적이다.
- **비전**: AI가 PRD·코드맥락·**최신 최고수준 레퍼런스와 대기업 채용 요구**를 사전에 분석하여, **임팩트 있는 해결전략**과 **표준 개발 명세서** 및 **AI 실행 프롬프트**를 자동 산출. 결과는 Notion에 기록되어 장기(2–3년) 커리어 자산으로 축적.

**핵심 가치**

1. **업무 효율/성과 극대화**: 리서치→문제정의→해결방안→테스트 계획까지 착수 시간을 단축.
2. **사전 리서치 우선(Brave MCP)**: “돌아가기만 하는 코드”를 넘어서 **대기업 요구 역량**과 업계 Best Practice에 부합하는 설계를 유도.
3. **체계적 축적**: Dev Spec/근거/프롬프트가 버전/추적 가능 형태로 누적.

---

## 1. 목표/비목표

**목표**

- **G1. 인입 명시화**: Notion PRD·회의록과 \*\*GitHub 레포 + 중점 파일 목록(`focus_files[]`)\*\*을 입력으로 받아 자동 수집·정규화.
- **G2. 표준 개발 명세서**: `현상 → 원인 분석 → 해결 방안 → 학습 포인트` 구조로 초안 자동 생성(근거 인용 필수).
- **G2.5. 사전 리서치/분석 강화(Brave MCP)**: 최근 12개월 **권위 소스 ≥5** + **대기업 채용공고 ≥3**를 분석하여 **Competency Map(요구역량↔솔루션/학습 포인트 매핑)** 생성.
- **G3. 대화형 리뷰 루프**: 섹션별 수정·Diff·근거 강화.
- **G4. AI 실행 프롬프트 산출**: 코드생성/테스트/리뷰 프롬프트 번들을 구조화 생성.
- **G5. Notion 발행 & 추적성**: 버전/메타/근거 링크 포함 발행 및 히스토리 보존.

**비목표(본 버전)**

- 다사용자/조직 권한, 광범위 툴(Jira/Linear 등) 통합, 코드/PR **자동 생성**, 블로그/이력서 자동화, **클라우드 오브젝트 스토리지(S3) 의존**은 제외.
- 사후 성과 분석·대시보드는 범위 밖(후속 단계).

---

## 2. 주요 사용자 & 사용 시나리오

- **개인 개발자(=유호준)**: 기능/프로젝트 착수 전 5분 이내에 고품질 Dev Spec과 실행 프롬프트를 확보하고 싶다.
- **시나리오**
  1. 사용자가 `source_notion_url`, `repo`, `focus_files[]`, `output_notion_url`을 제출.
  2. 서버가 Notion/GitHub를 수집·정규화하고 \*\*리서치 파이프라인(Brave)\*\*을 병렬 실행.
  3. AI가 리서치 결과 + 코드맥락 기반으로 Dev Spec 초안을 생성(근거 인용 포함).
  4. 사용자가 채팅형 리뷰로 수치/서술/트레이드오프 보강 → 부분 재생성.
  5. **AI 실행 프롬프트 번들** 확인 후 확정.
  6. Notion에 발행, 버전 태깅.

---

## 3. 사용자 흐름 (E2E)

1. **Intake 폼**(클라이언트) →

- 입력: `source_notion_url`, `repo`, `focus_files[]`, `output_notion_url`, `title(optional)`, `confidentiality(level)`
- OAuth 상태 확인(노션/깃허브)

1. **수집/분석 파이프라인**(서버) →

- Notion MCP: 페이지/하위 블록 Markdown Export
- GitHub MCP: 레포 트리, 최근 N PR/커밋/이슈, **focus_files AST/metrics**
- **Brave MCP(필수)**: 최신 레퍼런스/대기업 공고 수집→정규화→중복제거→랭킹
- **인덱싱**: MySQL 저장 + **FULLTEXT** 인덱스(초기) / 선택적 **JSON 임베딩** 저장 후 앱 레벨 재랭킹

1. **초안 생성** →

- Structured Output(JSON Schema) + 근거 인용(`code://`, `pr://`, `doc://`, `web://`)
- 리서치 요약/Competency Map 반영, 이미지 캡처는 필요시 **로컬 임시 파일**만 사용

1. **리뷰/수정 루프** →

- 섹션별 Diff, 지시문 패치, 정량 슬롯 TODO 해소
- “근거 강제” 옵션, 출처/날짜 자동 검증

1. **발행 & 아카이브** →

- Notion Markdown 업로드 + 메타블록(버전, 태그, 링크)
- 스냅샷은 **DB(JSON/MD) 저장** 방식으로 최소비용 운영

---

## 4. 기능 요구사항 (FR) & 수용 기준

### FR1. 소스 인입(Intake)

- AC1.1 필수 필드 검증, OAuth 유도
- AC1.2 제출 시 `{ jobId, projectId }` 반환, 진행상태 스트리밍

### FR2. Notion 문서 수집/정규화

- AC2.1 Markdown + 구조화 JSON 추출
- AC2.2 제목/태그/작성자/링크 메타
- AC2.3 100k자 규모 백그라운드 처리

### FR3. GitHub 리포/코드 분석

- AC3.1 레포 메타/트리, 최근 N PR/커밋/이슈
- \*\AC3.2 \\\*\*\*`focus_files`\*\***에 대해 AST/Complexity/변화이력/주요 시그니처 추출**

### FR4. 맥락 저장/검색(저비용)

- **AC4.1 MySQL 저장 + FULLTEXT 기반 1차 검색**
- **AC4.2 선택적 JSON 임베딩 저장 → 앱 레벨 재랭킹**(코사인 유사도)
- AC4.3 동일 입력 재요청 시 캐시/증분 업데이트, 사용자 격리

### FR5. 개발 명세서 초안 생성

- AC5.1 스키마 준수·누락 0
- AC5.2 섹션별 **근거 인용 ≥1**
- AC5.3 정량 슬롯 비어있으면 TODO 표시

### **FR6. 사전 리서치/분석(Brave MCP)**

- **AC6.1 최근 12개월 소스만 기본 채택, 출처/날짜/저자 메타 수집**
- **AC6.2 권위 소스 ≥5 + 대기업 채용공고 ≥3** 확보
- **AC6.3 Competency Map 생성(요구역량↔솔루션/학습 포인트 매핑) & 근거 링크**
- **AC6.4 저품질/중복 소스 제거 규칙 적용(도메인 allowlist/유사도 임계)**

### FR7. 대화형 리뷰/수정 루프

- AC7.1 섹션별 패치·부분 재생성
- AC7.2 Diff/이력/근거 로그
- AC7.3 무제한 반복, 자동 저장

### FR8. AI 실행 프롬프트 산출

- AC8.1 `ai_prompts.codegen/test/review` 3종 구성
- AC8.2 각 프롬프트에 **컨텍스트/제약/근거 링크** 포함
- AC8.3 모델/온톨로지 교체 가능(템플릿화)

### FR9. Notion 발행

- AC9.1 체크리스트 통과(정량/인용/TL;DR)
- AC9.2 Notion 업데이트 + 버전/링크 삽입
- AC9.3 스냅샷 DB 저장·URL 반환

### FR10. 워크스페이스/히스토리/권한

- 프로젝트 홈, 타임라인, 품질 점수
- OAuth 토큰 보안, 레드랙션 규칙

---

## 5. 비기능 요구사항 (NFR)

- **성능**: 초안 생성 TTV 60–180초(큐 사용)
- **가용성**: 재시도/백오프, 복구 가이드
- **확장성**: 단일 사용자 월 50건 안정
- **보안**: 토큰 암호화, PIPA 준수, 감사 로그
- **관측성**: 상관 ID, 단계 이벤트, 프롬프트/출력 버전 고정
- **비용**: 외부 스토리지 미사용, MySQL 단일 인스턴스부터 시작

---

## 6. 시스템 아키텍처

**구성요소**

- `apps/web`(Next.js): Intake/진행/리뷰/발행 UI
- `apps/api`(NestJS): REST, 큐 워커, MCP 클라이언트, 검색/재랭킹
- `packages/mcp-clients`: Notion/GitHub/Brave 래퍼
- DB: **MySQL 8.x**, 캐시/큐: Redis(BullMQ)

**데이터 플로우**

1. Web→API `/intake`
2. Worker: Notion/GitHub 수집 + **Brave 리서치** → 정규화/저장
3. Draft: 검색/재랭킹 컨텍스트로 LLM 생성
4. Web: 리뷰/Diff/패치
5. Publish: Notion 업데이트 + DB 스냅샷

---

## 7. 데이터 모델(요약)

- `user(id, email, display_name, created_at)`
- `project(id, user_id, title, source_notion_url, repo, output_notion_url, confidentiality, status)`
- `source_doc(id, project_id, type[notion|github|web], uri, sha, meta_json, content_md)`
- `embedding(id, source_doc_id, chunk_id, vector_json JSON, text, meta_json)`
- `research_source(id, project_id, kind[reference|job_posting], domain, url, title, author, published_at, summary_md, weight)`
- `competency_map(id, project_id, competency, evidence_ids JSON, mapped_solutions JSON, gaps JSON)`
- `spec_draft(id, project_id, version, json, md, quality_score, created_at)`
- `ai_prompt(id, project_id, draft_version, kind[codegen|test|review], content_md, created_at)`
- `feedback(id, draft_id, section_key, role[user|ai], message, created_at)`
- `iteration(id, project_id, from_version, to_version, diff_json, created_at)`
- `publish_log(id, project_id, draft_version, notion_page_id, url, created_at)`
- `oauth_token(id, user_id, provider, scope, enc_token, refreshed_at)`

---

## 8. 출력 스키마(Structured Spec JSON)

````json
{
  "title": "string",
  "summary": "TL;DR 3-5줄",
  "context": {
    "product": "string",
    "stakeholders": ["PM", "BE", "FE"],
    "constraints": ["데드라인", "성능 목표"]
  },
  "current_behavior": "markdown",
  "root_cause": [
    {
      "hypothesis": "string",
      "evidence": ["code://...", "pr://...", "doc://...", "web://..."]
    }
  ],
  "solutions": [
    {
      "approach": "string",
      "tradeoffs": ["string"],
      "tasks": ["checklist item"],
      "impact_metrics": { "conversion": "number?", "latency_ms": "number?" }
    }
  ],
  "learning_points": ["string"],
  "research_summary": {
    "sources": [{ "url": "", "title": "", "published_at": "", "note": "" }],
    "competency_map": [
      {
        "competency": "",
        "evidence": ["web://...", "job://..."],
        "applies_to": ["solutions[i]"]
      }
    ]
  },
  "ai_prompts": {
    "codegen": "markdown",
    "test": "markdown",
    "review": "markdown"
  },
  "appendix": { "links": ["..."], "snippets": ["```ts\\n...\\n```"] }
}
````

---

## 9. API 설계 (NestJS · REST)

### POST `/api/v1/projects/intake`

요청:

```json
{
  "source_notion_url": "string",
  "repo": "owner/name",
  "focus_files": ["src/foo.ts", "app/page.tsx"],
  "output_notion_url": "string",
  "title": "string?",
  "confidentiality": "public|internal|confidential"
}
```

응답: `{ jobId: string, projectId: string }`

### POST `/api/v1/projects/:id/research`

- 리서치 파이프라인 트리거(Brave), 상태 폴링/스트림 제공

### GET `/api/v1/drafts/:id`

- 초안 JSON+MD 반환, 섹션 키 포함

### PATCH `/api/v1/drafts/:id`

- 요청 `{ section_key, instruction, strict_citation }` → 부분 재생성 + Diff

### POST `/api/v1/drafts/:id/prompts`

- 현 초안을 기반으로 `ai_prompts` 생성/갱신

### POST `/api/v1/drafts/:id/publish`

- 요청 `{ checklist_ack: true }` → `{ notionUrl, version, snapshotUrl }`

에러 규격: `{ code, message, correlationId }`

---

## 10. LLM/검색 파이프라인

- **수집**: Notion, GitHub(코드/PR/커밋/이슈), Brave(레퍼런스/채용공고)
- **정규화**: Markdown + 메타(작성자, 날짜, 링크, 파일 경로)
- **검색/재랭킹**: MySQL FULLTEXT 1차 검색 → JSON 임베딩 기반 재랭킹(앱 레벨)
- **프롬프트 가드**: “근거를 반드시 인용, 추정은 TODO, 스키마 준수, 최근 12개월 우선”
- **출력 제약**: JSON Schema / citation schema `code://repo/path#L12-45`
- **품질체크**: 필수 필드/근거/날짜 검증, 저품질 소스 차단

---

## 11. MCP 통합

- **Notion MCP**: 페이지 조회/업데이트, 데이터베이스 메타, 백오프
- **GitHub MCP**: 트리/파일/PR/커밋/이슈, `focus_files` 우선 스캔
- **Brave MCP(필수)**: 레퍼런스/채용공고 수집, 중복제거/요약/랭킹

---

## 12. UX 설계(Next.js)

- **화면**
  1. Intake 폼
  2. 진행 뷰(타임라인/로그)
  3. **리서치 패널**(소스·채용공고·Competency Map·신뢰도/신선도)
  4. 초안 리뷰(Diff/근거/정량 슬롯)
  5. **AI 프롬프트 뷰**(codegen/test/review)
  6. 발행 확인(체크리스트)
- **상태머신**: `idle→submitting→queued→collecting→researching→drafting→review→publishing→done|error`

---

## 13. 품질 지표 & 로깅

- **지표**: 초안 TTV, **리서치 커버리지(권위소스/채용공고 수)**, **대기업 요건 매핑률**, 인용 커버리지, 발행율
- **로그**: 단계 이벤트, 프롬프트/모델 버전, 근거 유효성, 사용자 행동(익명화)

---

## 14. 테스트 전략

- 단위: MCP 모킹, 파서/Chunker, 스키마 밸리데이션
- 통합: 샘플 PRD/레포/채용공고로 E2E
- 회귀: 프롬프트/모델 버전 변경 시 골든세트 비교
- 성능: 100k자 문서 + 중형 레포 + 리서치 20소스 스트레스

---

## 15. 보안/권한

- OAuth 최소 범위, 토큰 KMS 암호화, 롤링 키, 사용 감시
- 데이터 분리(프로젝트/사용자), Redaction 규칙
- 감사 로그(발행/수정 이력)

---

## 16. 배포/운영

- 인프라: Docker, IaC(Terraform) 권장, Blue/Green
- 모니터링: OpenTelemetry + Grafana/Prom
- 백업: MySQL 일일 스냅샷(스토리지 최소화), 복구 리허설 분기 1회

---

## 17. 로드맵(요약)

- **M1 (2주)**: Intake→수집→**리서치**→초안→프롬프트→발행 E2E(MVP, 단일 사용자)
- **M2 (2–4주)**: 품질 점수, 체크리스트, Competency Map 시각화, 히스토리 타임라인
- **M3 (4–6주)**: 블로그/이력서 연동, Slack/메일 노티

---

## 18. 리스크 & 완화

- Notion/GitHub/Brave Rate Limit → 큐/백오프/캐시, 증분 동기화
- 저품질/편향 소스 → 도메인 allowlist, 다중 출처 교차검증, 날짜 필터
- 대형 레포 성능 → `focus_files` 우선, 파일 샘플링, AST/metrics 비동기화

---
